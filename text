import org.apache.spark.sql.{DataFrame, SparkSession}
import org.apache.spark.sql.functions._

object FootballETL {

  val jdbcUrl = "jdbc:postgresql://localhost:5432/your_database" // change DB name
  val dbUser = "postgres" // change if needed
  val dbPassword = "your_password" // change if needed
  val driverClass = "org.postgresql.Driver"

  def run()(implicit spark: SparkSession): Unit = {
    import spark.implicits._

    println("🔁 Extracting raw tables...")

    val countryDF = readTable("public.Country")
    val leagueDF = readTable("public.League")
    val teamDF = readTable("public.Team")
    val matchDF = readTable("public.Match")

    println(s"Extracted rows -> Country: ${countryDF.count()}, League: ${leagueDF.count()}, Team: ${teamDF.count()}, Match: ${matchDF.count()}")

    println("🔍 Running data quality checks on matches...")
    val matchCleanedDF = matchDF
      .filter($"season".isNotNull && $"date".isNotNull)

    // === DIMENSIONS ===
    val dimCountryDF = countryDF.select($"id".as("country_id"), $"name".as("country_name"))
    val dimLeagueDF = leagueDF.select($"id".as("league_id"), $"country_id", $"name".as("league_name"))
    val dimTeamDF = teamDF.select($"id".as("team_id"), $"team_api_id", $"team_fifa_api_id", $"team_long_name", $"team_short_name")

    // === FACT TABLES ===
    val factMatchDF = matchCleanedDF
      .select(
        $"id".as("match_id"),
        $"country_id",
        $"league_id",
        $"season",
        $"stage",
        $"date",
        $"home_team_api_id",
        $"away_team_api_id",
        $"home_team_goal",
        $"away_team_goal"
      )

    // Example: aggregate team-season performance
    val factTeamSeasonDF = factMatchDF
      .groupBy($"season", $"league_id", $"home_team_api_id".as("team_api_id"))
      .agg(
        count("*").as("matches_played"),
        sum(when($"home_team_goal" > $"away_team_goal", 1).otherwise(0)).as("wins"),
        sum(when($"home_team_goal" < $"away_team_goal", 1).otherwise(0)).as("losses"),
        sum(when($"home_team_goal" === $"away_team_goal", 1).otherwise(0)).as("draws")
      )

    // === LOAD TO POSTGRES ===
    println("✅ Writing to football_dw schema in Postgres...")
    writeToPostgres(dimCountryDF, "dim_country")
    writeToPostgres(dimLeagueDF, "dim_league")
    writeToPostgres(dimTeamDF, "dim_team")
    writeToPostgres(factMatchDF, "fact_match")
    writeToPostgres(factTeamSeasonDF, "fact_team_season")

    println("✅ Full ETL finished successfully")
  }

  private def readTable(tableName: String)(implicit spark: SparkSession): DataFrame = {
    spark.read
      .format("jdbc")
      .option("url", jdbcUrl)
      .option("dbtable", tableName)
      .option("user", dbUser)
      .option("password", dbPassword)
      .option("driver", driverClass)
      .load()
  }

  private def writeToPostgres(df: DataFrame, tableName: String): Unit = {
    df.write
      .format("jdbc")
      .option("url", jdbcUrl)
      .option("dbtable", s"football_dw.$tableName")
      .option("user", dbUser)
      .option("password", dbPassword)
      .option("driver", driverClass)
      .mode("overwrite")
      .save()
  }
}
