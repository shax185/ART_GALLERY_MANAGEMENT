SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [org.apache.logging.slf4j.SLF4JServiceProvider@2e4b8173]
SLF4J(W): Found provider [org.slf4j.simple.SimpleServiceProvider@70e8f8e]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [org.apache.logging.slf4j.SLF4JServiceProvider@2e4b8173]
Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
25/08/08 12:19:59 INFO SparkContext: Running Spark version 3.5.1
25/08/08 12:19:59 INFO SparkContext: OS info Windows 11, 10.0, amd64
25/08/08 12:19:59 INFO SparkContext: Java version 17.0.16
25/08/08 12:20:00 WARN Shell: Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
25/08/08 12:20:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/08/08 12:20:00 INFO ResourceUtils: ==============================================================
25/08/08 12:20:00 INFO ResourceUtils: No custom resources configured for spark.driver.
25/08/08 12:20:00 INFO ResourceUtils: ==============================================================
25/08/08 12:20:00 INFO SparkContext: Submitted application: Football ETL
25/08/08 12:20:00 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/08/08 12:20:00 INFO ResourceProfile: Limiting resource is cpu
25/08/08 12:20:00 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/08/08 12:20:00 INFO SecurityManager: Changing view acls to: shrohida
25/08/08 12:20:00 INFO SecurityManager: Changing modify acls to: shrohida
25/08/08 12:20:00 INFO SecurityManager: Changing view acls groups to: 
25/08/08 12:20:00 INFO SecurityManager: Changing modify acls groups to: 
25/08/08 12:20:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shrohida; groups with view permissions: EMPTY; users with modify permissions: shrohida; groups with modify permissions: EMPTY
25/08/08 12:20:01 INFO Utils: Successfully started service 'sparkDriver' on port 51174.
25/08/08 12:20:01 INFO SparkEnv: Registering MapOutputTracker
25/08/08 12:20:01 INFO SparkEnv: Registering BlockManagerMaster
25/08/08 12:20:01 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/08/08 12:20:01 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
Exception in thread "main" java.lang.IllegalAccessError: class org.apache.spark.storage.StorageUtils$ (in unnamed module @0xf58853c) cannot access class sun.nio.ch.DirectBuffer (in module java.base) because module java.base does not export sun.nio.ch to unnamed module @0xf58853c
	at org.apache.spark.storage.StorageUtils$.<init>(StorageUtils.scala:213)
	at org.apache.spark.storage.StorageUtils$.<clinit>(StorageUtils.scala)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.<init>(BlockManagerMasterEndpoint.scala:121)
	at org.apache.spark.SparkEnv$.$anonfun$create$9(SparkEnv.scala:358)
	at org.apache.spark.SparkEnv$.registerOrLookupEndpoint$1(SparkEnv.scala:295)
	at org.apache.spark.SparkEnv$.create(SparkEnv.scala:344)
	at org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)
	at org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:483)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)
	at org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)
	at Main$.main(Main.scala:7)
	at Main.main(Main.scala)
