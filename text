name := "FootballETL"

version := "0.1"

scalaVersion := "2.12.18"

libraryDependencies ++= Seq(
  // Spark core + SQL
  "org.apache.spark" %% "spark-core" % "3.5.1",
  "org.apache.spark" %% "spark-sql"  % "3.5.1",

  // PostgreSQL JDBC driver
  "org.postgresql" % "postgresql" % "42.7.3",

  // Logging for Spark
  "org.slf4j" % "slf4j-simple" % "2.0.13"
)

// Allow Spark to run locally without Hadoop install
Compile / run / fork := true

import org.apache.spark.sql.SparkSession

object Main {
  def main(args: Array[String]): Unit = {
    val spark = SparkSession.builder()
      .appName("Football ETL")
      .master("local[*]")
      .getOrCreate()

    println(s"Spark version: ${spark.version}")

    spark.stop()
  }
}
