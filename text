SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [org.apache.logging.slf4j.SLF4JServiceProvider@130161f7]
SLF4J(W): Found provider [org.slf4j.simple.SimpleServiceProvider@2c767a52]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [org.apache.logging.slf4j.SLF4JServiceProvider@130161f7]
Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
25/08/08 12:54:21 INFO SparkContext: Running Spark version 3.5.1
25/08/08 12:54:21 INFO SparkContext: OS info Windows 11, 10.0, amd64
25/08/08 12:54:21 INFO SparkContext: Java version 11.0.28
25/08/08 12:54:21 WARN Shell: Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
25/08/08 12:54:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/08/08 12:54:22 INFO ResourceUtils: ==============================================================
25/08/08 12:54:22 INFO ResourceUtils: No custom resources configured for spark.driver.
25/08/08 12:54:22 INFO ResourceUtils: ==============================================================
25/08/08 12:54:22 INFO SparkContext: Submitted application: Football ETL
25/08/08 12:54:22 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/08/08 12:54:22 INFO ResourceProfile: Limiting resource is cpu
25/08/08 12:54:22 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/08/08 12:54:22 INFO SecurityManager: Changing view acls to: shrohida
25/08/08 12:54:22 INFO SecurityManager: Changing modify acls to: shrohida
25/08/08 12:54:22 INFO SecurityManager: Changing view acls groups to: 
25/08/08 12:54:22 INFO SecurityManager: Changing modify acls groups to: 
25/08/08 12:54:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shrohida; groups with view permissions: EMPTY; users with modify permissions: shrohida; groups with modify permissions: EMPTY
25/08/08 12:54:23 INFO Utils: Successfully started service 'sparkDriver' on port 53745.
25/08/08 12:54:23 INFO SparkEnv: Registering MapOutputTracker
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/C:/Users/shrohida/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.5.1/spark-unsafe_2.12-3.5.1.jar) to constructor java.nio.DirectByteBuffer(long,int)
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
25/08/08 12:54:23 INFO SparkEnv: Registering BlockManagerMaster
25/08/08 12:54:23 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/08/08 12:54:23 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/08/08 12:54:23 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/08/08 12:54:24 INFO DiskBlockManager: Created local directory at C:\Users\shrohida\AppData\Local\Temp\blockmgr-694d8879-c4f9-4ba0-8054-1111a0d5556a
25/08/08 12:54:24 INFO MemoryStore: MemoryStore started with capacity 2.2 GiB
25/08/08 12:54:24 INFO SparkEnv: Registering OutputCommitCoordinator
25/08/08 12:54:24 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
25/08/08 12:54:24 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/08/08 12:54:24 INFO Executor: Starting executor ID driver on host 10.237.0.184
25/08/08 12:54:24 INFO Executor: OS info Windows 11, 10.0, amd64
25/08/08 12:54:24 INFO Executor: Java version 11.0.28
25/08/08 12:54:24 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/08/08 12:54:24 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@57f9b467 for default.
25/08/08 12:54:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53793.
25/08/08 12:54:24 INFO NettyBlockTransferService: Server created on 10.237.0.184:53793
25/08/08 12:54:24 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/08/08 12:54:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.237.0.184, 53793, None)
25/08/08 12:54:24 INFO BlockManagerMasterEndpoint: Registering block manager 10.237.0.184:53793 with 2.2 GiB RAM, BlockManagerId(driver, 10.237.0.184, 53793, None)
25/08/08 12:54:24 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.237.0.184, 53793, None)
25/08/08 12:54:24 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.237.0.184, 53793, None)
âœ… Spark Session started successfully!
25/08/08 12:54:25 INFO SparkContext: SparkContext is stopping with exitCode 0.
25/08/08 12:54:25 INFO SparkUI: Stopped Spark web UI at http://10.237.0.184:4040
25/08/08 12:54:25 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/08/08 12:54:25 INFO MemoryStore: MemoryStore cleared
25/08/08 12:54:25 INFO BlockManager: BlockManager stopped
25/08/08 12:54:25 INFO BlockManagerMaster: BlockManagerMaster stopped
25/08/08 12:54:25 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/08/08 12:54:25 INFO SparkContext: Successfully stopped SparkContext
25/08/08 12:54:25 INFO ShutdownHookManager: Shutdown hook called
25/08/08 12:54:25 INFO ShutdownHookManager: Deleting directory C:\Users\shrohida\AppData\Local\Temp\spark-b44526ab-21c0-4569-9669-b8977cdd0b39
