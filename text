package etl

import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}
import org.apache.spark.sql.functions._
import org.apache.spark.sql.types._
import org.apache.spark.sql.expressions.Window
import java.sql.DriverManager
import java.util.Properties

object FullLeagueETL {

  // ---------- CONFIG ----------
  val jdbcUrl = "jdbc:postgresql://localhost:5432/football"
  val dbUser  = "postgres"
  val dbPass  = "your_password"   // <<-- set your password
  val dbDriver = "org.postgresql.Driver"
  val targetSchema = "football_dw"
  val keepLastNForForm = 5 // rolling form window
  val writeCoalescePartitions = 4 // reduce small writes into Postgres
  val minRivalryMeetings = 10 // threshold for rivalries table
  val relevantLeagues = Set(
    "England Premier League",
    "France Ligue 1",
    "Germany 1. Bundesliga",
    "Italy Serie A",
    "Spain LIGA BBVA"
  )
  // ----------------------------

  private def ensureSchemaExists(): Unit = {
    Class.forName(dbDriver)
    val conn = DriverManager.getConnection(jdbcUrl, dbUser, dbPass)
    try {
      val stmt = conn.createStatement()
      stmt.execute(s"CREATE SCHEMA IF NOT EXISTS $targetSchema;")
      stmt.close()
      println(s"âœ… Ensured schema: $targetSchema")
    } finally conn.close()
  }

  private def jdbcProps: Properties = {
    val p = new Properties()
    p.setProperty("user", dbUser)
    p.setProperty("password", dbPass)
    p.setProperty("driver", dbDriver)
    p
  }

  /**
   * Read the given table. If tableOrQuery starts with "(" treat as subquery (pushdown).
   * This keeps compatibility but enables pushdown if needed.
   */
  private def readTable(spark: SparkSession, tableOrQuery: String): DataFrame = {
    val df = if (tableOrQuery.trim.startsWith("(")) {
      spark.read.jdbc(jdbcUrl, tableOrQuery, jdbcProps)
    } else {
      spark.read.jdbc(jdbcUrl, s""""public"."$tableOrQuery"""", jdbcProps)
    }
    df
  }

  private def writeTable(dfIn: DataFrame, fullTableName: String): Unit = {
    // small optimization: coalesce to avoid many tiny writes to jdbc
    val df = if (dfIn.rdd.getNumPartitions > writeCoalescePartitions) dfIn.coalesce(writeCoalescePartitions) else dfIn
    df.write
      .mode(SaveMode.Overwrite)
      .jdbc(jdbcUrl, fullTableName, jdbcProps)
    // avoid counting (expensive). If you need the count, call it where necessary externally.
    println(s"âœ… Wrote table $fullTableName")
  }

  private def createIndexes(): Unit = {
    Class.forName(dbDriver)
    val conn = DriverManager.getConnection(jdbcUrl, dbUser, dbPass)
    try {
      val stmt = conn.createStatement()
      val idxs = Seq(
        s"CREATE INDEX IF NOT EXISTS idx_fact_match_league_season ON $targetSchema.fact_match (league_id, season);",
        s"CREATE INDEX IF NOT EXISTS idx_fact_match_home_team ON $targetSchema.fact_match (home_team_id);",
        s"CREATE INDEX IF NOT EXISTS idx_fact_match_away_team ON $targetSchema.fact_match (away_team_id);",
        s"CREATE INDEX IF NOT EXISTS idx_fact_team_season_team ON $targetSchema.fact_team_season (team_id, season);",
        s"CREATE INDEX IF NOT EXISTS idx_fact_league_season_league ON $targetSchema.fact_league_season (league_id, season);"
      )
      idxs.foreach(sql => stmt.execute(sql))
      stmt.close()
      println("âœ… Created indexes on DW tables")
    } finally conn.close()
  }

  def run(spark: SparkSession): Unit = {
    import spark.implicits._
    spark.sparkContext.setLogLevel("WARN")

    ensureSchemaExists()

    // === EXTRACT ===
    println("ðŸ” Extracting raw tables...")

    // Use pushdown for League so we only read relevant leagues
    val leagueNamesEscaped = relevantLeagues.map(name => s"'${name.replace("'", "''")}'").mkString(",")
    val leagueQuery = s"(SELECT id, country_id, name FROM public.\"League\" WHERE name IN ($leagueNamesEscaped)) t_league"

    val tCountry = readTable(spark, "Country")
    val tLeague = readTable(spark, leagueQuery).persist() // reused
    val tTeam = readTable(spark, "Team")
    val tMatch = readTable(spark, "Match")
    val tPlayer = try { readTable(spark, "Player") } catch { case _: Throwable => spark.emptyDataFrame }
    val tPlayerAttr = try { readTable(spark, "Player_Attributes") } catch { case _: Throwable => spark.emptyDataFrame }
    val tTeamAttr = try { readTable(spark, "Team_Attributes") } catch { case _: Throwable => spark.emptyDataFrame }

    // avoid heavy full counts; just sample existence + small counts for logging
    println(s"Extracted tables (sample): League rows=${tLeague.limit(5).count()}, Match cols=${tMatch.columns.length}, Team cols=${tTeam.columns.length}")

    // === DIMENSION FILTERING ===
    val dimLeagueFiltered = tLeague
      .select(
        col("id").cast(IntegerType).alias("league_id"),
        col("country_id").cast(IntegerType),
        trim(col("name")).alias("league_name")
      )
      .na.drop(Seq("league_id"))
      .dropDuplicates("league_id")
      .persist()

    val relevantCountryIds = dimLeagueFiltered.select("country_id").distinct()

    val dimCountryFiltered = tCountry
      .select(
        col("id").cast(IntegerType).alias("country_id"),
        trim(col("name")).alias("country_name")
      )
      .join(relevantCountryIds, Seq("country_id"), "inner")
      .na.drop(Seq("country_id"))
      .dropDuplicates("country_id")

    // === FACT MATCH CLEAN + ENRICH ===
    val matchCols = Seq(
      "id", "country_id", "league_id", "season", "stage", "date",
      "match_api_id", "home_team_api_id", "away_team_api_id",
      "home_team_goal", "away_team_goal"
    ).filter(c => tMatch.columns.contains(c))

    val factMatchRaw = tMatch.select(matchCols.map(col): _*)

    val factMatchTyped = factMatchRaw
      .withColumn("match_id", col("id").cast(IntegerType))
      .withColumn("league_id", col("league_id").cast(IntegerType))
      .withColumn("country_id", col("country_id").cast(IntegerType))
      .withColumn("season", col("season").cast(StringType))
      .withColumn("date", to_timestamp(col("date")))
      .withColumn("home_team_id", col("home_team_api_id").cast(IntegerType))
      .withColumn("away_team_id", col("away_team_api_id").cast(IntegerType))
      .withColumn("home_team_goal", col("home_team_goal").cast(IntegerType))
      .withColumn("away_team_goal", col("away_team_goal").cast(IntegerType))
      .select("match_id", "league_id", "country_id", "season", "date", "home_team_id", "away_team_id", "home_team_goal", "away_team_goal")

    // Filter matches to relevant leagues & countries
    val factMatchFiltered = factMatchTyped
      .join(dimLeagueFiltered.select("league_id"), Seq("league_id"), "inner")
      .join(dimCountryFiltered.select("country_id"), Seq("country_id"), "inner")

    val factMatchClean = factMatchFiltered
      .filter(col("home_team_goal").isNotNull && col("away_team_goal").isNotNull && col("date").isNotNull)
      .filter(col("home_team_goal") >= 0 && col("away_team_goal") >= 0)
      .dropDuplicates("match_id")
      .persist()

    val factMatchEnriched = factMatchClean
      .withColumn("result",
        when(col("home_team_goal") > col("away_team_goal"), lit("Home Win"))
          .when(col("home_team_goal") < col("away_team_goal"), lit("Away Win"))
          .otherwise(lit("Draw"))
      )
      .withColumn("goal_difference", col("home_team_goal") - col("away_team_goal"))
      .withColumn("home_points",
        when(col("home_team_goal") > col("away_team_goal"), lit(3))
          .when(col("home_team_goal") === col("away_team_goal"), lit(1))
          .otherwise(lit(0))
      )
      .withColumn("away_points",
        when(col("away_team_goal") > col("home_team_goal"), lit(3))
          .when(col("away_team_goal") === col("home_team_goal"), lit(1))
          .otherwise(lit(0))
      )
      .withColumn("season_start_year", regexp_extract(col("season"), """(\d{4})""", 1).cast(IntegerType))
      .withColumn("match_week", weekofyear(col("date")))
      .withColumn("match_date", to_date(col("date")))
      .persist()

    // === RELEVANT TEAMS (for filtering dim_team and players) ===
    val relevantTeamIds = factMatchEnriched
      .select("home_team_id").withColumnRenamed("home_team_id", "team_id")
      .union(factMatchEnriched.select(col("away_team_id").alias("team_id")))
      .distinct()
      .persist()

    val dimTeam = tTeam
      .withColumn("team_id", when(col("team_api_id").isNotNull, col("team_api_id")).otherwise(col("id")))
      .select(
        col("team_id").cast(IntegerType),
        trim(col("team_long_name")).alias("team_name"),
        trim(col("team_short_name")).alias("team_short_name")
      )
      .na.drop(Seq("team_id"))
      .dropDuplicates("team_id")
      .join(relevantTeamIds, Seq("team_id"), "inner")
      .persist()

    // === WRITE DIMENSIONS & FACT MATCH ===
    writeTable(dimCountryFiltered, s"$targetSchema.dim_country")
    writeTable(dimLeagueFiltered.select("league_id", "league_name", "country_id"), s"$targetSchema.dim_league")
    writeTable(dimTeam, s"$targetSchema.dim_team")
    writeTable(factMatchEnriched.select(
      "match_id", "league_id", "country_id", "season", "match_date",
      "home_team_id", "away_team_id", "home_team_goal", "away_team_goal",
      "result", "goal_difference", "home_points", "away_points"
    ), s"$targetSchema.fact_match")

    // === TEAM-SEASON AGGREGATES ===
    val homePerspective = factMatchEnriched.select(
      col("match_id"), col("season"), col("league_id"), col("match_date"),
      col("home_team_id").alias("team_id"), col("away_team_id").alias("opponent_team_id"),
      col("home_team_goal").alias("goals_for"), col("away_team_goal").alias("goals_against"),
      col("home_points").alias("points")
    ).withColumn("is_home", lit(true))

    val awayPerspective = factMatchEnriched.select(
      col("match_id"), col("season"), col("league_id"), col("match_date"),
      col("away_team_id").alias("team_id"), col("home_team_id").alias("opponent_team_id"),
      col("away_team_goal").alias("goals_for"), col("home_team_goal").alias("goals_against"),
      col("away_points").alias("points")
    ).withColumn("is_home", lit(false))

    val teamMatchPerspective = homePerspective.unionByName(awayPerspective)
      .filter(col("team_id").isNotNull)
      .persist()

    val factTeamSeason = teamMatchPerspective.groupBy("season", "league_id", "team_id")
      .agg(
        countDistinct("match_id").alias("matches_played"),
        sum(when(col("points") === 3, 1).otherwise(0)).alias("wins"),
        sum(when(col("points") === 1, 1).otherwise(0)).alias("draws"),
        sum(when(col("points") === 0, 1).otherwise(0)).alias("losses"),
        sum("goals_for").alias("goals_for"),
        sum("goals_against").alias("goals_against"),
        (sum("goals_for") - sum("goals_against")).alias("goal_difference"),
        sum("points").alias("points"),
        round(sum("points") / countDistinct("match_id"), 3).alias("win_rate")
      )
      .persist()

    writeTable(factTeamSeason, s"$targetSchema.fact_team_season")

    // === LEAGUE-SEASON AGGREGATES ===
    val factLeagueSeason = factTeamSeason.groupBy("season", "league_id")
      .agg(
        sum("matches_played").alias("total_matches"),
        round(avg("goals_for"), 2).alias("avg_goals_per_team"),
        round(avg("points"), 2).alias("avg_points_per_team"),
        max("points").alias("points_max")
      )

    writeTable(factLeagueSeason, s"$targetSchema.fact_league_season")

    // === ROLLING TEAM FORM ===
    val w = Window.partitionBy("team_id").orderBy(col("match_date").cast("timestamp")).rowsBetween(-keepLastNForForm, -1)
    val teamForm = teamMatchPerspective
      .withColumn("rolling_goals_for_lastN", sum("goals_for").over(w))
      .withColumn("rolling_goals_against_lastN", sum("goals_against").over(w))
      .withColumn("rolling_points_lastN", sum("points").over(w))
      .withColumn("form_matches", count("match_id").over(w))
      .select("team_id", "league_id", "season", "match_date", "form_matches", "rolling_points_lastN", "rolling_goals_for_lastN", "rolling_goals_against_lastN")
      .na.fill(0)
      .persist()

    writeTable(teamForm, s"$targetSchema.fact_team_form")

    // === TEAM PROGRESS (cumulative points over season timeline) ===
    val progressWindow = Window.partitionBy("season", "team_id").orderBy("match_date").rowsBetween(Window.unboundedPreceding, Window.currentRow)
    val teamProgress = teamMatchPerspective
      .withColumn("cumulative_points", sum("points").over(progressWindow))
      .select("season", "league_id", "team_id", "match_date", "cumulative_points")
      .persist()

    writeTable(teamProgress, s"$targetSchema.fact_team_progress")

    // === LEAGUE STANDINGS (ranked) ===
    val standingsWindow = Window.partitionBy("season", "league_id").orderBy(col("points").desc, col("goal_difference").desc)
    val leagueStandings = factTeamSeason
      .withColumn("rank", row_number().over(standingsWindow))
      .select("season", "league_id", "team_id", "matches_played", "wins", "draws", "losses", "goals_for", "goals_against", "goal_difference", "points", "win_rate", "rank")
      .persist()

    writeTable(leagueStandings, s"$targetSchema.fact_league_standings")

    // === HEAD-TO-HEAD AGGREGATES ===
    val pairDf = factMatchEnriched.select("match_id", "match_date", "home_team_id", "away_team_id", "home_team_goal", "away_team_goal")
      .withColumn("team_a", least(col("home_team_id"), col("away_team_id")))
      .withColumn("team_b", greatest(col("home_team_id"), col("away_team_id")))
      .withColumn("a_goals", when(col("team_a") === col("home_team_id"), col("home_team_goal")).otherwise(col("away_team_goal")))
      .withColumn("b_goals", when(col("team_b") === col("away_team_id"), col("away_team_goal")).otherwise(col("home_team_goal")))

    val headToHead = pairDf.groupBy("team_a", "team_b")
      .agg(
        count("match_id").alias("meetings"),
        sum(when(col("a_goals") > col("b_goals"), 1).otherwise(0)).alias("a_wins"),
        sum(when(col("a_goals") === col("b_goals"), 1).otherwise(0)).alias("draws"),
        sum(when(col("a_goals") < col("b_goals"), 1).otherwise(0)).alias("b_wins"),
        sum("a_goals").alias("a_goals_total"),
        sum("b_goals").alias("b_goals_total"),
        round(sum(when(col("a_goals") > col("b_goals"), 1).otherwise(0)) / count("match_id"), 3).alias("a_win_rate"),
        round(sum(when(col("a_goals") < col("b_goals"), 1).otherwise(0)) / count("match_id"), 3).alias("b_win_rate")
      )
      .persist()

    writeTable(headToHead, s"$targetSchema.fact_head_to_head")

    // === RIVALRIES (filter headToHead by meetings threshold) ===
    val rivalries = headToHead.filter(col("meetings") >= minRivalryMeetings)
    writeTable(rivalries, s"$targetSchema.fact_rivalries")

    // === HIGH SCORING MATCHES ===
    val highScoringMatches = factMatchEnriched
      .withColumn("total_goals", col("home_team_goal") + col("away_team_goal"))
      .select("match_id", "season", "league_id", "match_date", "home_team_id", "away_team_id", "home_team_goal", "away_team_goal", "total_goals")
      .orderBy(col("total_goals").desc)
      .persist()

    writeTable(highScoringMatches, s"$targetSchema.fact_high_scoring_matches")

    // === GOAL DISTRIBUTION (season + league level aggregates suitable for viz) ===
    val goalDistribution = factMatchEnriched
      .withColumn("total_goals", col("home_team_goal") + col("away_team_goal"))
      .groupBy("season", "league_id")
      .agg(
        round(avg("total_goals"), 3).alias("avg_total_goals"),
        expr("percentile_approx(total_goals, 0.5)").alias("median_total_goals"),
        min("total_goals").alias("min_total_goals"),
        max("total_goals").alias("max_total_goals"),
        count("*").alias("matches_count")
      )

    writeTable(goalDistribution, s"$targetSchema.fact_goal_distribution")

    // === PLAYER SEASON SNAPSHOT (only relevant players) ===
    if (!tPlayerAttr.rdd.isEmpty()) {
      // naive relevantPlayers detection: players where player_api_id in matches (needs a proper player-team link for production)
      val playersInMatches = tPlayer.select(col("player_api_id")).distinct() // this may be large; adjust if you have a roster link
      val playerAttr = tPlayerAttr
        .withColumn("date", to_date(col("date")))
        .withColumn("year", year(col("date")))
        .join(playersInMatches, Seq("player_api_id"), "inner")

      val win = Window.partitionBy("player_api_id", "year").orderBy(col("date").desc)
      val playerYearSnapshot = playerAttr.withColumn("rn", row_number().over(win)).filter(col("rn") === 1).drop("rn")

      writeTable(
        playerYearSnapshot.select(
          col("player_api_id"),
          col("year"),
          col("overall_rating"),
          col("potential")
        ),
        s"$targetSchema.dim_player_year_snapshot"
      )
    }

    // === VALIDATIONS (lightweight) ===
    println("ðŸ” Running post-load validations (lightweight)...")

    // check whether any league_id in fact_match is missing from dim_league (use small join + limit for speed)
    val factMatchDF = spark.read.jdbc(jdbcUrl, s""""$targetSchema"."fact_match"""", jdbcProps)
    val dimLeagueDF = spark.read.jdbc(jdbcUrl, s""""$targetSchema"."dim_league"""", jdbcProps)
    val missingLeagueFK = factMatchDF.join(dimLeagueDF, Seq("league_id"), "left_anti")
    val missingCount = missingLeagueFK.limit(1).count() // only detect presence
    if (missingCount > 0) {
      println(s"âš  Warning: some fact_match rows have league_id that don't exist in dim_league. (investigate)")
    } else {
      println("âœ… All league_ids in fact_match have matching entries in dim_league.")
    }

    // check duplicate match_id quick
    val dupMatches = factMatchDF.groupBy("match_id").count().filter("count > 1").limit(1).count()
    if (dupMatches > 0) {
      println(s"âš  Duplicate match_id found (quick check).")
    } else {
      println("âœ… No duplicate match_ids found (quick check).")
    }

    createIndexes()

    // unpersist intermediate heavy DFs to free memory
    Seq(tLeague, dimLeagueFiltered, factMatchClean, factMatchEnriched, relevantTeamIds, teamMatchPerspective, factTeamSeason, teamForm, teamProgress, leagueStandings, headToHead, highScoringMatches).foreach { df =>
      try { if (df != null) df.unpersist() } catch { case _: Throwable => () }
    }

    println("âœ… Full ETL finished successfully.")
  }
}
